<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[爬取拉勾网的爬虫相关职位的数据]]></title>
    <url>%2F2019%2F05%2F30%2F%E7%88%AC%E5%8F%96%E6%8B%89%E5%8B%BE%E7%BD%91%E7%9A%84%E7%88%AC%E8%99%AB%E7%9B%B8%E5%85%B3%E8%81%8C%E4%BD%8D%E7%9A%84%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[用requests请求拉勾网，并将爬取到的数据存储到MongoDB中。 分析​ 首先，我想爬取的是与爬虫相关的职位，所以我在拉勾上直接搜索爬虫。 ​ 连续翻页，可以发现，拉勾网的网址url是不变的，然后可以使用浏览器，禁用Javascript资源的加载，重新刷新网页，发现网页的内容是无法加载出来的。这就更印证了拉勾网的前端数据是使用Ajex来加载的。 ​ 然后使用chorme浏览器的检查功能，如下图，发现网页返回的多是json格式的数据。 ​ 再查看请求信息，发现是post请求，请求的数据如下图，且pn为页数，kd为搜索的关键字。并且请求的url是https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false。点击进去是禁止访问的。 ​ 再分析请求头，拉勾网除了一般的都需要的Cookie和User-Agent外还有一个特别的条件就是Referer。 一顿分析完之后就可以开始构建爬虫了。 构造爬虫​ 我一开始爬的时候直接用requests带上ua、cookie和referer的请求头去请求搜索页。结果返回的结果不是想要的。 ​ 然后问了问大佬，是拉勾的反爬机制中会验证cookie，直接用搜索后的cookie是不行的，然后我就拿拉勾网搜索首页的cookie来请求，就请求成功了。大家可以自己试试。 ​ 好了，既然可以成功请求并且返回网页数据了，就可以开始分析网页的结构来解析出想要的数据了。 ​ 拉钩网搜索页的结构很简单，是json格式的数据，职位的信息是在content下的positionResult下的result里面。 ​ 这里使用python的好处就来了，python视json格式的数据为字典dict类型的数据。处理起来也就跟处理字典类型的数据一样。所以直接对返回的json格式按键值取出数据即可。 ​ 这样就可以爬取出一页的职位信息了。 ​ 我们想要爬取的多页的数据，我们就来写一个结构化的爬虫，用一个循环来爬取多页的数据。并且可以将爬到的数据存在mongoDB中了。 ​ 使用mongodb只需要几条命令就可以了。 ​ 首先导入MongoClient；然后实例化client一个对象。client对象用来指向我们想要连接的数据库。然后指向一个表，mongodb里表叫collection。后面就可以通过insert来插入数据了。 ​ 我的爬虫是这样的，一开始想要先爬十页的数据，可是怕了五页就停了。大家可以自己试试。 ​ 然后我想了想，应该是拉钩网的反爬机制限制同一个cookie来短时间内多次请求。既然这样，我可以每爬一页前用requests获取一个新的cookie来请求。 ​ 因为需要用搜索首页的cookie所以就用requests请求搜索首页，获取到的cookie放到请求搜索页中的请求中。 ​ 这样每爬一页都用新的cookie就不怕cookie过期了。 ​ 可是～～～愉快的爬了几个职位信息之后，发现我的ip被禁了，现在的网站反爬太多了。这里就需要换新的ip来爬了，我们可以构建自己的ip池，当ip被禁了之后，从IP池中取出一个新的ip来爬取网页。这部分后面再说，今天先这样啦～掰掰]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[测试文章]]></title>
    <url>%2F2019%2F05%2F27%2F%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[这是一篇测试文章，欢迎关注我的博客: https://LeuRutao.github.io/]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>介绍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F27%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
